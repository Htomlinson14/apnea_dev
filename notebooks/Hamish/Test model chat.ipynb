{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to test the chosen model on the held out chat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Imports scikit-learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import bespoke\n",
    "import rail_utils\n",
    "from rail_utils import PlotModels\n",
    "import PointsModel\n",
    "import rail_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_file = '../../data/processed/chat_data_standard_train.csv'\n",
    "train_data = pd.read_csv(train_file)\n",
    "test_file = '../../data/processed/chat_data_standard_test.csv'\n",
    "test_data = pd.read_csv(test_file)\n",
    "\n",
    "# Define variables\n",
    "admission_variables = ['gender_Male', 'ethnicity_Hispanic','ethnicity_Black', 'ethnicity_White', 'ethnicity_Asian', \\\n",
    "                       'term', 'bmi', 'age', 'allergies_Yes', 'asthma_Yes', 'gerd_Yes', 'tonsilsize_3-4', 'zscore']\n",
    "test_variable = ['ahi']\n",
    "continuous_variables = [\"bmi\", \"age\", 'zscore']\n",
    "reference_variables = ['reference: osa18', 'reference: psq', 'reference: ess']\n",
    "\n",
    "# Variables to ignore based on distributions\n",
    "# ignore_variables = ['ethnicity Black', 'ethnicity Hispanic', 'gerd_Yes', 'tonsilsize_3-4', 'age']\n",
    "ignore_variables = []\n",
    "\n",
    "final_variables = list(set(admission_variables) - set(ignore_variables))\n",
    "continuous_variables = list(set(continuous_variables) - set(ignore_variables))\n",
    "\n",
    "# Set thresholds\n",
    "ahi_thresh = 5\n",
    "ref_thresh = {'reference: osa18': 60, 'reference: psq': 0.33, 'reference: ess': 8.01}\n",
    "\n",
    "# Set up training set\n",
    "ytrain_orig = pd.Series(train_data['ahi']>ahi_thresh, index=train_data.index)\n",
    "xtrain_orig = train_data[final_variables]\n",
    "ytest_orig = pd.Series(test_data['ahi']>ahi_thresh, index=test_data.index)\n",
    "xtest_orig = test_data[final_variables]\n",
    "yref = test_data[reference_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set cross-val AUC is: 0.607\n"
     ]
    }
   ],
   "source": [
    "ytrain = ytrain_orig.copy()\n",
    "xtrain = xtrain_orig.copy()\n",
    "ytest = ytest_orig.copy()\n",
    "xtest = xtest_orig.copy()\n",
    "\n",
    "models = {'best_model': svm.SVC(probability=True, kernel='linear'), 'kang_model': PointsModel.PointsModel()}\n",
    "\n",
    "pipeline = [[preprocessing.StandardScaler(), continuous_variables], [PCA(n_components=10), 'all']]\n",
    "\n",
    "test_models = PlotModels(models=models, pipeline=pipeline)\n",
    "\n",
    "[xtrain, ytrain], [xtest, ytest] = test_models._process_pipeline([xtrain, ytrain], [xtest, ytest])\n",
    "\n",
    "# Test cross-validation score on training set\n",
    "auroc_scores = cross_val_score(models['best_model'], xtrain, ytrain, cv=5, scoring ='roc_auc')\n",
    "print('Training set cross-val AUC is: {:0.3f}'.format(auroc_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model train and test\n",
    "\n",
    "models['best_model'].fit(xtrain, ytrain)\n",
    "pred_proba = models['best_model'].predict_proba(xtest)[:, 1]\n",
    "auc = metrics.roc_auc_score(ytest, pred_proba)\n",
    "fpr, tpr, _ = metrics.roc_curve(ytest, pred_proba)\n",
    "test_models._plot_vars['best_model'] = [fpr, tpr, auc, '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test kang model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n",
      "         Current function value: 0.640050\n",
      "         Iterations: 35\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679176\n",
      "         Iterations 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/statsmodels/base/model.py:496: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "ytrain = ytrain_orig.copy()\n",
    "xtrain = xtrain_orig.copy()\n",
    "ytest = ytest_orig.copy()\n",
    "xtest = xtest_orig.copy()\n",
    "\n",
    "models['kang_model'].fit(xtrain, ytrain)\n",
    "pred_proba = models['kang_model'].predict_proba(xtest)[:, 1]\n",
    "auc = metrics.roc_auc_score(ytest, pred_proba)\n",
    "fpr, tpr, _ = metrics.roc_curve(ytest, pred_proba)\n",
    "test_models._plot_vars['kang_model'] = [fpr, tpr, auc, '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model (AUC: 0.570, Sens: 0.766, Spec: 0.409)\n",
      "kang_model (AUC: 0.359, Sens: 0.000, Spec: 1.000)\n"
     ]
    }
   ],
   "source": [
    "test_models._make_label()\n",
    "print(test_models._plot_vars['best_model'][3])\n",
    "print(test_models._plot_vars['kang_model'][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test reference surveys on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference: osa18 --> Sensitivity = 0.449, Specificity = 0.730\n",
      "Match sensitivity for reference: osa18 --> Sensitivity = 0.477, Specificity = 0.600\n",
      "Match specificity for reference: osa18 --> Sensitivity = 0.299, Specificity = 0.730\n",
      "\n",
      "reference: psq --> Sensitivity = 0.841, Specificity = 0.287\n",
      "Match sensitivity for reference: psq --> Sensitivity = 0.850, Specificity = 0.278\n",
      "Match specificity for reference: psq --> Sensitivity = 0.804, Specificity = 0.313\n",
      "\n",
      "reference: ess --> Sensitivity = 0.355, Specificity = 0.713\n",
      "Match sensitivity for reference: ess --> Sensitivity = 0.383, Specificity = 0.687\n",
      "Match specificity for reference: ess --> Sensitivity = 0.308, Specificity = 0.722\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ytrain = ytrain_orig.copy()\n",
    "xtrain = xtrain_orig.copy()\n",
    "ytest = ytest_orig.copy()\n",
    "xtest = xtest_orig.copy()\n",
    "\n",
    "[xtrain, ytrain], [xtest, ytest] = test_models._process_pipeline([xtrain, ytrain], [xtest, ytest])\n",
    "\n",
    "models['best_model'].fit(xtrain, ytrain)\n",
    "pred_proba = models['best_model'].predict_proba(xtest)[:, 1]\n",
    "auc = metrics.roc_auc_score(ytest, pred_proba)\n",
    "fpr, tpr, _ = metrics.roc_curve(ytest, pred_proba)\n",
    "test_models._plot_vars['best_model'] = [fpr, tpr, auc, '']\n",
    "\n",
    "\n",
    "ref_sens_spec = {ref_metric: [] for ref_metric in reference_variables}\n",
    "\n",
    "for ref_metric in reference_variables:\n",
    "    ypred = pd.Series(yref[ref_metric]>=ref_thresh[ref_metric], index=yref.index)\n",
    "    sensitivity, specificity = rail_utils.sens_and_spec(ytest, ypred)\n",
    "    ref_sens_spec[ref_metric] = [sensitivity, specificity]\n",
    "\n",
    "# Compare sensitivity and specificity to reference values\n",
    "for ref_metric in reference_variables:\n",
    "    print('{} --> Sensitivity = {:0.3f}, Specificity = {:0.3f}'.format(ref_metric, \\\n",
    "    ref_sens_spec[ref_metric][0], ref_sens_spec[ref_metric][1]))\n",
    "    sensitivity, specificity = rail_utils.match_sens(fpr, tpr, ref_sens_spec[ref_metric][0])\n",
    "    print('Match sensitivity for {} --> Sensitivity = {:0.3f}, Specificity = {:0.3f}'.format(ref_metric, \\\n",
    "    sensitivity, specificity))\n",
    "    sensitivity, specificity = rail_utils.match_spec(fpr, tpr, ref_sens_spec[ref_metric][1])\n",
    "    print('Match specificity for {} --> Sensitivity = {:0.3f}, Specificity = {:0.3f}'.format(ref_metric, \\\n",
    "    sensitivity, specificity))\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
