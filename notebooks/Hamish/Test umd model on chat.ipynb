{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to train best umd model on umd data, and test on chat data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports general\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Imports scikit-learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Import bespoke\n",
    "import PointsModel\n",
    "import rail_utils\n",
    "from rail_utils import PlotModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load UMD data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_file = '../../data/processed/umd_data_standard_all.csv'\n",
    "train_data = pd.read_csv(train_file)\n",
    "test_file = '../../data/processed/chat_data_standard_all.csv'\n",
    "test_data = pd.read_csv(test_file)\n",
    "\n",
    "# Define variables\n",
    "admission_variables = ['gender_Male', 'ethnicity_Hispanic','ethnicity_Black', 'ethnicity_White', 'ethnicity_Asian', \\\n",
    "                       'term', 'bmi', 'age', 'allergies_Yes', 'asthma_Yes', 'gerd_Yes', 'tonsilsize_3-4', 'zscore']\n",
    "test_variable = ['ahi']\n",
    "continuous_variables = [\"bmi\", \"age\", 'zscore']\n",
    "reference_variables = ['reference: osa18', 'reference: psq', 'reference: ess']\n",
    "\n",
    "# Variables to ignore based on distributions\n",
    "# ignore_variables = ['ethnicity Black', 'ethnicity Hispanic', 'gerd_Yes', 'tonsilsize_3-4', 'age']\n",
    "ignore_variables = []\n",
    "\n",
    "final_variables = list(set(admission_variables) - set(ignore_variables))\n",
    "continuous_variables = list(set(continuous_variables) - set(ignore_variables))\n",
    "\n",
    "# Set thresholds\n",
    "ahi_thresh = 5\n",
    "ref_thresh = {'reference: osa18': 60, 'reference: psq': 0.33, 'reference: ess': 8.01}\n",
    "\n",
    "# Set up training and test set\n",
    "ytrain_orig = pd.Series(train_data['ahi']>ahi_thresh, index=train_data.index)\n",
    "xtrain_orig = train_data[final_variables]\n",
    "ytest_orig = pd.Series(test_data['ahi']>ahi_thresh, index=test_data.index)\n",
    "xtest_orig = test_data[final_variables]\n",
    "yref = test_data[reference_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set cross-val AUC is: 0.786\n"
     ]
    }
   ],
   "source": [
    "ytrain = ytrain_orig.copy()\n",
    "xtrain = xtrain_orig.copy()\n",
    "ytest = ytest_orig.copy()\n",
    "xtest = xtest_orig.copy()\n",
    "\n",
    "models = {'best_model': LogisticRegression(penalty='l1'), 'kang_model': PointsModel.PointsModel()}\n",
    "\n",
    "pipeline = [[preprocessing.StandardScaler(), continuous_variables],\n",
    "            [preprocessing.PolynomialFeatures(degree=2), 'from before'],\n",
    "            [PCA(n_components=6), 'from before']]\n",
    "\n",
    "test_models = PlotModels(models=models, pipeline=pipeline)\n",
    "\n",
    "[xtrain, ytrain], [xtest, ytest] = test_models._process_pipeline([xtrain, ytrain], [xtest, ytest])\n",
    "\n",
    "# Test cross-validation score on training set\n",
    "auroc_scores = cross_val_score(models['best_model'], xtrain, ytrain, cv=5, scoring ='roc_auc')\n",
    "print('Training set cross-val AUC is: {:0.3f}'.format(auroc_scores.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Model train and test\n",
    "models['best_model'].fit(xtrain, ytrain)\n",
    "pred_proba = models['best_model'].predict_proba(xtest)[:, 1]\n",
    "auc = metrics.roc_auc_score(ytest, pred_proba)\n",
    "fpr, tpr, _ = metrics.roc_curve(ytest, pred_proba)\n",
    "test_models._plot_vars['best_model'] = [fpr, tpr, auc, '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test kang model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.605563\n",
      "         Iterations 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.608981\n",
      "         Iterations 5\n"
     ]
    }
   ],
   "source": [
    "ytrain = ytrain_orig.copy()\n",
    "xtrain = xtrain_orig.copy()\n",
    "ytest = ytest_orig.copy()\n",
    "xtest = xtest_orig.copy()\n",
    "\n",
    "models['kang_model'].fit(xtrain, ytrain)\n",
    "pred_proba = models['kang_model'].predict_proba(xtest)[:, 1]\n",
    "auc = metrics.roc_auc_score(ytest, pred_proba)\n",
    "fpr, tpr, _ = metrics.roc_curve(ytest, pred_proba)\n",
    "test_models._plot_vars['kang_model'] = [fpr, tpr, auc, '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_model (AUC: 0.575, Sens: 0.570, Spec: 0.576)\n",
      "kang_model (AUC: 0.415, Sens: 0.042, Spec: 0.974)\n"
     ]
    }
   ],
   "source": [
    "test_models._make_label()\n",
    "print(test_models._plot_vars['best_model'][3])\n",
    "print(test_models._plot_vars['kang_model'][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test reference surveys on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference: osa18 --> Sensitivity = 0.360, Specificity = 0.701\n",
      "Match sensitivity for reference: osa18 --> Sensitivity = 0.360, Specificity = 0.771\n",
      "Match specificity for reference: osa18 --> Sensitivity = 0.411, Specificity = 0.710\n",
      "\n",
      "reference: psq --> Sensitivity = 0.822, Specificity = 0.251\n",
      "Match sensitivity for reference: psq --> Sensitivity = 0.822, Specificity = 0.238\n",
      "Match specificity for reference: psq --> Sensitivity = 0.804, Specificity = 0.255\n",
      "\n",
      "reference: ess --> Sensitivity = 0.364, Specificity = 0.636\n",
      "Match sensitivity for reference: ess --> Sensitivity = 0.364, Specificity = 0.762\n",
      "Match specificity for reference: ess --> Sensitivity = 0.458, Specificity = 0.636\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models['best_model'].fit(xtrain, ytrain)\n",
    "pred_proba = models['best_model'].predict_proba(xtest)[:, 1]\n",
    "auc = metrics.roc_auc_score(ytest, pred_proba)\n",
    "fpr, tpr, _ = metrics.roc_curve(ytest, pred_proba)\n",
    "\n",
    "ref_sens_spec = {ref_metric: [] for ref_metric in reference_variables}\n",
    "\n",
    "for ref_metric in reference_variables:\n",
    "    ypred = pd.Series(yref[ref_metric]>=ref_thresh[ref_metric], index=yref.index)\n",
    "    sensitivity, specificity = rail_utils.sens_and_spec(ytest, ypred)\n",
    "    ref_sens_spec[ref_metric] = [sensitivity, specificity]\n",
    "\n",
    "# Compare sensitivity and specificity to reference values\n",
    "for ref_metric in reference_variables:\n",
    "    print('{} --> Sensitivity = {:0.3f}, Specificity = {:0.3f}'.format(ref_metric, \\\n",
    "    ref_sens_spec[ref_metric][0], ref_sens_spec[ref_metric][1]))\n",
    "    sensitivity, specificity = rail_utils.match_sens(fpr, tpr, ref_sens_spec[ref_metric][0])\n",
    "    print('Match sensitivity for {} --> Sensitivity = {:0.3f}, Specificity = {:0.3f}'.format(ref_metric, \\\n",
    "    sensitivity, specificity))\n",
    "    sensitivity, specificity = rail_utils.match_spec(fpr, tpr, ref_sens_spec[ref_metric][1])\n",
    "    print('Match specificity for {} --> Sensitivity = {:0.3f}, Specificity = {:0.3f}'.format(ref_metric, \\\n",
    "    sensitivity, specificity))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
